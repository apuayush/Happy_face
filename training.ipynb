{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurvnit/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train = h5py.File('dataset/train_happy.h5', \"r\")\n",
    "    X_train_orig = np.array(train[\"train_set_x\"][:]) # your train set features\n",
    "    Y_train_orig = np.array(train[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('dataset/test_happy.h5', \"r\")\n",
    "    X_test_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    Y_test_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    Y_train = Y_train_orig.reshape((1, Y_train_orig.shape[0]))\n",
    "    Y_test = Y_test_orig.reshape((1, Y_test_orig.shape[0]))\n",
    "    \n",
    "    return X_train_orig, Y_train, X_test_orig, Y_test, classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_o, Y_train_o, X_test_o, Y_test_o, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1) (600, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_o/255\n",
    "X_test = X_test_o/255\n",
    "\n",
    "Y_train = Y_train_o.T\n",
    "Y_test = Y_test_o.T\n",
    "\n",
    "print(Y_train.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "   \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = HappyModel((64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 1.6683 - acc: 0.6267\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.2670 - acc: 0.8767\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1618 - acc: 0.9367\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1408 - acc: 0.9433\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1351 - acc: 0.9483\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1128 - acc: 0.9617\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0901 - acc: 0.9683\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0772 - acc: 0.9683\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.1115 - acc: 0.9633\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0602 - acc: 0.9833\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0463 - acc: 0.9850\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0682 - acc: 0.9700\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0591 - acc: 0.9833\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0605 - acc: 0.9833\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0339 - acc: 0.9900\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0369 - acc: 0.9917\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0252 - acc: 0.9933\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0263 - acc: 0.9917\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0308 - acc: 0.9867\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0417 - acc: 0.9900\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0304 - acc: 0.9900\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0415 - acc: 0.9850\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0495 - acc: 0.9867\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0419 - acc: 0.9833\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0492 - acc: 0.9767\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0962 - acc: 0.9667\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0365 - acc: 0.9867\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0341 - acc: 0.9883\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0443 - acc: 0.9833\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0579 - acc: 0.9750\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0320 - acc: 0.9900\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0497 - acc: 0.9883\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0340 - acc: 0.9883\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0290 - acc: 0.9933\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0131 - acc: 0.9967\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0242 - acc: 0.9883\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0286 - acc: 0.9933\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0235 - acc: 0.9950\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0200 - acc: 0.9883\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0268 - acc: 0.9933\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0164 - acc: 0.9933\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0413 - acc: 0.9850\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0183 - acc: 0.9950\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0161 - acc: 0.9917\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0224 - acc: 0.9967\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0111 - acc: 0.9983\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0558 - acc: 0.9767\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0475 - acc: 0.9817\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0354 - acc: 0.9900\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0351 - acc: 0.9867\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0333 - acc: 0.9867\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0396 - acc: 0.9867\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0418 - acc: 0.9817\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0400 - acc: 0.9867\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0269 - acc: 0.9900\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0252 - acc: 0.9867\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0556 - acc: 0.9817\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0293 - acc: 0.9900\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0610 - acc: 0.9867\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0413 - acc: 0.9900\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0288 - acc: 0.9833\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0186 - acc: 0.9967\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0175 - acc: 0.9950\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 0.0050 - acc: 0.9983\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0055 - acc: 0.9967\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0136 - acc: 0.9983\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0060 - acc: 0.9967\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 6.8063e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0062 - acc: 0.9967\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0067 - acc: 0.9950\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0224 - acc: 0.9967\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0125 - acc: 0.9933\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0166 - acc: 0.9917\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0322 - acc: 0.9933\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0333 - acc: 0.9883\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0255 - acc: 0.9900\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0090 - acc: 0.9950\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0118 - acc: 0.9950\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0284 - acc: 0.9950\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0599 - acc: 0.9817\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0073 - acc: 0.9967\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 0.0221 - acc: 0.9950A: 2s - loss: 0.0180 \n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 8.0571e-04 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 9.5581e-04 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0020 - acc: 0.9983\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0142 - acc: 0.9967\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0158 - acc: 0.9967\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0105 - acc: 0.9967\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 7.7969e-04 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 9.0105e-04 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 4.1399e-04 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 1.9579e-04 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 8.2995e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b76841470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train, epochs=100, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64/150 [===========>..................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x=X_test, y=Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def save_model(file):\n",
    "    print(\"Creating Model At: \",file) \n",
    "    start_time = time.time()\n",
    "    \n",
    "    json_model = model.to_json()\n",
    "    model.save_weights(\"weights.h5\")\n",
    "    \n",
    "    with open(file, \"w\") as json_file:\n",
    "        json_file.write(json_model)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time-start_time\n",
    "    print(\"Model Created: \",total_time, \" seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model At:  model.json\n",
      "Model Created:  0.03480887413024902  seconds\n"
     ]
    }
   ],
   "source": [
    "save_model('model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes= True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img.resize(64,64,3)\n",
    "    print(img.shape)\n",
    "    k = model.predict(x=np.array([img]))[0][0]\n",
    "    print(k)\n",
    "    if k>0.66:\n",
    "        print(\"Happy in the picture\")\n",
    "    elif k<0.33:\n",
    "        print(\"sad in the picture\")\n",
    "    else:\n",
    "        print(\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "1.0\n",
      "Happy in the picture\n",
      "(64, 64, 3)\n",
      "1.0\n",
      "Happy in the picture\n"
     ]
    }
   ],
   "source": [
    "test(model,'test/pp.jpeg')\n",
    "test(model, 'test/my_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
